#process.py
import sys
import os
import cv2
import json
import math
import time
import torch
import logging
import traceback
import threading
import numpy as np
from collections import deque
from datetime import datetime
from ultralytics import YOLO
from PyQt5.QtCore import QThread, pyqtSignal, Qt, QTimer
from PyQt5.QtWidgets import (
    QApplication, QWidget, QPushButton, QLabel, QFileDialog, QVBoxLayout,
    QSlider, QGroupBox, QFormLayout, QMessageBox, QSpinBox, QHBoxLayout
)
from PyQt5.QtGui import QImage, QPixmap  # ì´ ì¤„ ì¶”ê°€
import queue
from detection_strategies import DetectionStrategyManager, VehicleOverlapStrategy, SizeRangeStrategy, VehicleDistanceStrategy, GravityDirectionStrategy, DirectionAlignmentStrategy, VehicleAssociationStrategy
import csv  # csv ëª¨ë“ˆ ì¶”ê°€

# ì‹±ê¸€í†¤ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì €ì¥í•  ì „ì—­ ë³€ìˆ˜
_model_instance = None
logging.getLogger("ultralytics").setLevel(logging.WARNING)

##########################
# ìŠ¤í”¼ë„ˆ(Spinner) ë° ëª¨ë¸ ë¡œë”© ë˜í¼
##########################
def spinner_task(stop_event):
    spinner_chars = ['|', '/', '-', '\\']
    idx = 0
    while not stop_event.is_set():
        sys.stdout.write(f"\rëª¨ë¸ ë¡œë”© ì¤‘... {spinner_chars[idx]}")
        sys.stdout.flush()
        idx = (idx + 1) % len(spinner_chars)
        time.sleep(0.1)

    sys.stdout.write("\rëª¨ë¸ ë¡œë”© ì™„ë£Œ!     \n")
    sys.stdout.flush()


def load_model_with_spinner(model_path="yolov8n.pt"):
    """
    ìŠ¤í”¼ë„ˆë¥¼ í‘œì‹œí•˜ë©´ì„œ ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    ì‹±ê¸€í†¤ íŒ¨í„´ì„ ì ìš©í•˜ì—¬ ëª¨ë¸ì´ í•œ ë²ˆë§Œ ë¡œë“œë˜ë„ë¡ í•¨
    """
    global _model_instance

    # ì´ë¯¸ ëª¨ë¸ì´ ë¡œë“œë˜ì–´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ë°˜í™˜
    if _model_instance is not None:
        return _model_instance

    stop_event = threading.Event()
    spinner_thread = threading.Thread(target=spinner_task, args=(stop_event,))
    spinner_thread.start()

    try:
        _model_instance = YOLO(model_path)
    except Exception as e:
        logging.error(f"ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        stop_event.set()
        spinner_thread.join()
        raise

    stop_event.set()
    spinner_thread.join()
    return _model_instance


##########################
# ì„¤ì • í´ë˜ìŠ¤
##########################
class Config:
    def __init__(self):
        # ê¸°ì¡´ ì„¤ì •
        self.min_size = 30
        self.max_size = 300
        self.yolo_confidence_value = 0.35
        self.gravity_direction_threshold = 7  # ì¤‘ë ¥ ë°©í–¥ ì„ê³„ê°’
        self.batch_size = 4
        self.output_dir = "output"
        self.distance_trash = 300  # 300ìœ¼ë¡œ ìˆ˜ì •

        # ì¹´ìš´íŠ¸ ì¶©ì¡± ì—¬ë¶€ë¥¼ ìœ„í•œ ë³€ìˆ˜ ì¶”ê°€
        self.min_frame_count_for_violation = 7  # ìœ„ë°˜ íŒì •ì„ ìœ„í•œ ìµœì†Œ í”„ë ˆì„ ì¹´ìš´íŠ¸

        # ìƒˆë¡œìš´ ì „ëµ ê´€ë ¨ ì„¤ì •
        self.horizontal_direction_threshold = 5  # ìˆ˜í‰ ì´ë™ ì„ê³„ê°’
        self.vehicle_overlap_threshold = 0.01  # ì°¨ëŸ‰ ê²¹ì¹¨ ë¹„ìœ¨ ì„ê³„ê°’ (1%ë¡œ ë³€ê²½ - ì•½ê°„ì´ë¼ë„ ê²¹ì¹˜ë©´ ë°°ì œ)
        self.max_vehicle_distance = 200  # ì°¨ëŸ‰ê³¼ ì˜¤ë¸Œì íŠ¸ ê°„ ìµœëŒ€ ê±°ë¦¬ (í”½ì…€)

        # ê°ì§€ ë¡œì§ ì„¤ì •
        self.detection_logic = "ALL"  # "ANY": ì–´ëŠ í•˜ë‚˜ë¼ë„ ì¶©ì¡±, "ALL": ëª¨ë‘ ì¶©ì¡±

        # ë””ë²„ê¹… ê´€ë ¨ ì„¤ì • ì¶”ê°€
        self.debug_detection = False  # ê°ì²´ ê²€ì¶œ ë””ë²„ê¹… ê¸°ë³¸ê°’ì€ False


# Config ê°ì²´ ìƒì„±
config = Config()


def update_config(new_config):
    """
    ì™¸ë¶€(ì˜ˆ: ui.py)ì—ì„œ ì „ë‹¬ë°›ì€ ì„¤ì •ê°’ì„ ê¸€ë¡œë²Œ configì— ë°˜ì˜.
    """
    global config
    try:
        config.min_size = new_config.min_size
        config.max_size = new_config.max_size
        config.yolo_confidence_value = new_config.yolo_confidence_value
        config.gravity_direction_threshold = new_config.gravity_direction_threshold
        config.distance_trash = new_config.distance_trash
        config.batch_size = new_config.batch_size

        logger.info("Config ì—…ë°ì´íŠ¸ ì™„ë£Œ:")
        logger.info(f"min_size={config.min_size}, max_size={config.max_size}, "
                    f"yolo_confidence={config.yolo_confidence_value}, "
                    f"gravity_direction_threshold={config.gravity_direction_threshold}, "
                    f"distance_trash={config.distance_trash}, "
                    f"batch_size={config.batch_size}")
    except Exception as e:
        logger.error(f"ì„¤ì • ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


##########################
# LOG ë””ë ‰í† ë¦¬ ë° ë¡œê·¸ íŒŒì¼ ì„¤ì •
##########################
LOG_DIR = "LOG"
os.makedirs(LOG_DIR, exist_ok=True)

log_filename = os.path.join(LOG_DIR, f"video_processing_{datetime.now().strftime('%Y%m%d')}.log")

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s: %(message)s',
    handlers=[
        logging.FileHandler(log_filename),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

########################################
# CUDA ì „ìš© ë¡œê±° ì„¤ì • (íŒŒì¼ë§Œ)
########################################
cuda_logger = logging.getLogger("cuda_info")
cuda_logger.setLevel(logging.INFO)
cuda_logger.propagate = False

cuda_file_handler = logging.FileHandler(log_filename)
cuda_file_handler.setLevel(logging.INFO)
cuda_logger.addHandler(cuda_file_handler)

cuda_logger.info(f"CUDA Available: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    try:
        cuda_logger.info(f"CUDA Version: {torch.version.cuda}")
        cuda_logger.info(f"PyTorch Version: {torch.__version__}")
        cuda_logger.info(f"Device Name: {torch.cuda.get_device_name(0)}")
    except Exception as e:
        cuda_logger.error(f"CUDA ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {str(e)}")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
cuda_logger.info(f"Using device: {device}")

torch.backends.cudnn.enabled = True

# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(config.output_dir, exist_ok=True)


def exception_hook(exctype, value, tb):
    logger.error("Uncaught exception: " + ''.join(traceback.format_exception(exctype, value, tb)))
    sys.__excepthook__(exctype, value, tb)


sys.excepthook = exception_hook


##########################
# EuclideanDistTracker í´ë˜ìŠ¤
##########################
class EuclideanDistTracker:
    """ê°„ë‹¨í•œ ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê¸°ë°˜ ê°ì²´ ì¶”ì ê¸°"""

    def __init__(self):
        self.objects = {}  # {object_id: (x, y, w, h)}
        self.next_object_id = 0
        self.distance_threshold = 50

    def update(self, detections):
        if not detections:
            return []

        updated_objects = {}
        assigned_ids = set()

        for (new_x, new_y, new_w, new_h) in detections:
            matched = False
            new_center = (new_x + new_w // 2, new_y + new_h // 2)
            for object_id, (old_x, old_y, old_w, old_h) in self.objects.items():
                if object_id in assigned_ids:
                    continue
                old_center = (old_x + old_w // 2, old_y + old_h // 2)
                distance = math.sqrt((new_center[0] - old_center[0]) ** 2 + (new_center[1] - old_center[1]) ** 2)

                if distance < self.distance_threshold:
                    updated_objects[object_id] = (new_x, new_y, new_w, new_h)
                    assigned_ids.add(object_id)
                    matched = True
                    break

            if not matched:
                updated_objects[self.next_object_id] = (new_x, new_y, new_w, new_h)
                assigned_ids.add(self.next_object_id)
                self.next_object_id += 1

        self.objects = updated_objects
        return [(x, y, w, h, object_id) for object_id, (x, y, w, h) in updated_objects.items()]


##########################
# ROI ì„¤ì • ì €ì¥/ë¡œë“œ í•¨ìˆ˜
##########################
ROI_SETTINGS_FILE = "roi_settings.json"


def save_roi_settings(roi_x, roi_y, roi_width, roi_height, min_size, max_size):
    """ROI ì„¤ì •ì„ JSON íŒŒì¼ë¡œ ì €ì¥"""
    try:
        roi_data = {
            "roi_x": roi_x,
            "roi_y": roi_y,
            "roi_width": roi_width,
            "roi_height": roi_height,
            "min_size": min_size,
            "max_size": max_size,
        }
        with open(ROI_SETTINGS_FILE, "w") as file:
            json.dump(roi_data, file, indent=4)
        logger.info("ROI ì„¤ì • ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"ROI ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {str(e)}")


def load_roi_settings():
    """JSON íŒŒì¼ì—ì„œ ROI ì„¤ì • ë¡œë“œ, ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜"""
    logger.debug("load_roi_settings í•¨ìˆ˜ í˜¸ì¶œë¨.")
    try:
        with open(ROI_SETTINGS_FILE, "r") as file:
            roi_data = json.load(file)
            logger.info(f"ROI ë°ì´í„° ë¡œë“œ ì„±ê³µ: {roi_data}")
            return (
                max(0, roi_data.get("roi_x", 0)),
                max(0, roi_data.get("roi_y", 300)),
                max(1, roi_data.get("roi_width", 800)),
                max(1, roi_data.get("roi_height", 150)),
                max(1, roi_data.get("min_size", 50)),
                max(1, roi_data.get("max_size", 400)),
            )
    except FileNotFoundError:
        logger.warning(f"ROI ì„¤ì • íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return 0, 300, 800, 150, 50, 400
    except json.JSONDecodeError as e:
        logger.error(f"ROI ì„¤ì • íŒŒì¼ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤: {str(e)}")
        return 0, 300, 800, 150, 50, 400
    except Exception as e:
        logger.error(f"ROI ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}, ê¸°ë³¸ê°’ ì‚¬ìš©")
        return 0, 300, 800, 150, 50, 400


##########################
# VideoWriterThread í´ë˜ìŠ¤
##########################
class VideoWriterThread(threading.Thread):
    """ë¹„ë””ì˜¤ ì €ì¥ì„ ë‹´ë‹¹í•˜ëŠ” ìŠ¤ë ˆë“œ í´ë˜ìŠ¤"""

    def __init__(self, write_queue, config, roi_x, roi_y, roi_width, roi_height):
        super().__init__()
        self.write_queue = write_queue
        self.config = config
        self.roi_x = roi_x
        self.roi_y = roi_y
        self.roi_width = roi_width
        self.roi_height = roi_height
        self.daemon = True
        self._stop_event = threading.Event()
        # ìˆ˜ì •: video_saved_signalì„ ì§ì ‘ ì „ë‹¬ë°›ì§€ëŠ” ì•ŠìŒ (ë©”ì¸ VideoThreadì—ì„œ ê´€ë¦¬)
        self.start()

    def stop(self):
        """ìŠ¤ë ˆë“œ ì •ì§€ ì‹ í˜¸ë¥¼ ì„¤ì •"""
        self._stop_event.set()
        # ì¢…ë£Œ ì‹ í˜¸ë¥¼ íì— ë„£ì–´ ë¸”ë¡œí‚¹ ìƒíƒœì˜ get()ë¥¼ í•´ì œ
        self.write_queue.put((None, None))

    def stopped(self):
        """ìŠ¤ë ˆë“œê°€ ì •ì§€ ìƒíƒœì¸ì§€ í™•ì¸"""
        return self._stop_event.is_set()

    def run(self):
        """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
        while not self.stopped():
            try:
                # íƒ€ì„ì•„ì›ƒì„ ì„¤ì •í•˜ì—¬ ì£¼ê¸°ì ìœ¼ë¡œ ì •ì§€ ì‹ í˜¸ë¥¼ í™•ì¸
                pre_frames, roi_frames = self.write_queue.get(timeout=1.0)
                if pre_frames is None and roi_frames is None:
                    if self.stopped():
                        break
                    continue

                video_path = self.capture_video(pre_frames, roi_frames)
                self.write_queue.task_done()

                # ë¹„ë””ì˜¤ ì €ì¥ ì™„ë£Œ ì‹œ ê²½ë¡œ ê¸°ë¡ (ë¡œê·¸ë§Œ ë‚¨ê¹€, ì‹ í˜¸ëŠ” ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ì²˜ë¦¬)
                if video_path:
                    logger.info(f"VideoWriterThread: ë¹„ë””ì˜¤ ì €ì¥ ì™„ë£Œ - {video_path}")
            except queue.Empty:
                # íƒ€ì„ì•„ì›ƒ ë°œìƒ - ì •ì§€ ì‹ í˜¸ í™•ì¸ í›„ ê³„ì†
                continue
            except Exception as e:
                logger.error(f"VideoWriterThread ì˜¤ë¥˜: {str(e)}")
                logger.error(traceback.format_exc())

    def capture_video(self, pre_frames, roi_frames=None):
        """ì´ë²¤íŠ¸ ê°ì§€ ì‹œ ë¹„ë””ì˜¤ ì €ì¥"""
        if not pre_frames or len(pre_frames) == 0:
            logger.error("ì €ì¥í•  í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None

        timestamp = time.strftime("%Y%m%d_%H%M%S")
        video_path = os.path.join(self.config.output_dir, f"trash_event_{timestamp}.avi")

        fps = 30  # ë” ë¶€ë“œëŸ¬ìš´ ì˜ìƒì„ ìœ„í•´ FPS ì¦ê°€

        # ì²« í”„ë ˆì„ì„ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ í¬ê¸° ê²°ì •
        sample_frame = pre_frames[0]
        frame_height, frame_width = sample_frame.shape[:2]

        fourcc = cv2.VideoWriter_fourcc(*'MJPG')

        try:
            # ì „ì²´ í”„ë ˆì„ í¬ê¸°ë¡œ ì €ì¥
            out = cv2.VideoWriter(video_path, fourcc, fps, (frame_width, frame_height))
            logger.info(
                f"ì“°ë ˆê¸° íˆ¬ê¸° ê°ì§€! ì˜ìƒ ì €ì¥ ì‹œì‘: {video_path} (í¬ê¸°: {frame_width}x{frame_height}, FPS: {fps}, í”„ë ˆì„ ìˆ˜: {len(pre_frames)})")

            # ëª¨ë“  í”„ë ˆì„ì„ ìˆœì„œëŒ€ë¡œ ì €ì¥
            for frame in pre_frames:
                out.write(frame)

            # roi_framesê°€ ìˆìœ¼ë©´ ì¶”ê°€ë¡œ ì €ì¥ (í˜„ì¬ ì½”ë“œì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
            if roi_frames and len(roi_frames) > 0:
                for frame in roi_frames:
                    out.write(frame)

            out.release()
            logger.info(f"ì˜ìƒ ì €ì¥ ì™„ë£Œ: {video_path} (ì´ {len(pre_frames)} í”„ë ˆì„)")

            # ë¹„ë””ì˜¤ ì €ì¥ ì™„ë£Œ í›„ ê²½ë¡œ ë°˜í™˜ - ì´ ë¹„ë””ì˜¤ ê²½ë¡œê°€ VideoThreadë¡œ ì „ë‹¬ë¨
            return video_path

        except Exception as e:
            logger.error(f"ì˜ìƒ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(traceback.format_exc())
            if 'out' in locals():
                out.release()
            return None


##########################
# FrameReaderThread í´ë˜ìŠ¤
##########################
class FrameReaderThread(threading.Thread):
    """
    OpenCV VideoCapture ë””ì½”ë”©ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ìˆ˜í–‰í•´,
    I/O ë³‘ëª©ì„ ì¤„ì´ê¸° ìœ„í•œ í´ë˜ìŠ¤.
    """

    def __init__(self, video_path, frame_queue, run_flag):
        super().__init__()
        self.video_path = video_path
        self.frame_queue = frame_queue
        self.run_flag = run_flag  # VideoThreadì™€ ê³µìœ (ë©ˆì¶¤ ì‹œì ì„ ì²´í¬)
        self.daemon = True
        self.start()

    def run(self):
        """í”„ë ˆì„ ì½ê¸° ë©”ì¸ ë£¨í”„"""
        try:
            cap = cv2.VideoCapture(self.video_path)
            if not cap.isOpened():
                logger.error(f"ë””ì½”ë”© ìŠ¤ë ˆë“œ: ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.video_path}")
                self.frame_queue.put(None)  # ì¢…ë£Œ ì‹ í˜¸
                return

            frame_count = 0
            while self.run_flag.is_set():
                ret, frame = cap.read()
                if not ret:
                    logger.info(f"ë””ì½”ë”© ìŠ¤ë ˆë“œ: ë” ì´ìƒ í”„ë ˆì„ì´ ì—†ìŒ(EOF), ì´ {frame_count} í”„ë ˆì„ ì²˜ë¦¬ë¨")
                    break

                # íê°€ ê°€ë“ ì°¨ë©´ ì ì‹œ ëŒ€ê¸° (I/O í­ì£¼ ë°©ì§€)
                while self.run_flag.is_set() and self.frame_queue.full():
                    time.sleep(0.01)

                # í”„ë ˆì„ì„ íì— ë„£ëŠ”ë‹¤
                if self.run_flag.is_set():  # ì¤‘ê°„ì— ì •ì§€ ì‹ í˜¸ê°€ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë‹¤ì‹œ í™•ì¸
                    self.frame_queue.put(frame)
                    frame_count += 1

            cap.release()
            # ì¢…ë£Œ ì‹ í˜¸ë¡œ Noneì„ í‘¸ì‹œ
            self.frame_queue.put(None)
            logger.info("ë””ì½”ë”© ìŠ¤ë ˆë“œ ì¢…ë£Œ")
        except Exception as e:
            logger.error(f"ë””ì½”ë”© ìŠ¤ë ˆë“œì—ì„œ ì˜ˆì™¸ ë°œìƒ: {str(e)}")
            logger.error(traceback.format_exc())
            self.frame_queue.put(None)


##########################
# VideoThread í´ë˜ìŠ¤
##########################
class VideoThread(QThread):
    """ë¹„ë””ì˜¤ ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” QThread í´ë˜ìŠ¤"""
    change_pixmap_signal = pyqtSignal(np.ndarray)
    video_saved_signal = pyqtSignal(str)  # ë¹„ë””ì˜¤ ì €ì¥ ì™„ë£Œ ì‹œê·¸ë„ ì¶”ê°€
    littering_detected_signal = pyqtSignal(tuple, str, float, dict)  # ì“°ë ˆê¸° íˆ¬ê¸° ê°ì§€ ì‹œê·¸ë„ ì¶”ê°€

    def __init__(
            self, video_path, min_size, max_size, min_box_size,
            roi_x, roi_y, roi_width, roi_height, config
    ):
        super().__init__()
        self.video_path = video_path
        self.min_size = min_size
        self.max_size = max_size
        self.min_box_size = min_box_size
        self.roi_x = roi_x
        self.roi_y = roi_y
        self.roi_width = roi_width
        self.roi_height = roi_height
        self._run_flag = True
        self.config = config

        # ë°°ì¹˜ ì²˜ë¦¬ ê´€ë ¨ ë½
        self.batch_lock = threading.Lock()
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì • ì €ì¥
        self.device = device

        try:
            # ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ëª¨ë¸ ë¡œë“œ
            self.model = load_model_with_spinner("yolov8n.pt")

            # ì•ˆì „í•œ ëª¨ë¸ ì´ˆê¸°í™” (CUDA í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°)
            try:
                # CUDAê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ê³  ì•ˆì „í•œ ê²½ìš°ì—ë§Œ GPU ì‚¬ìš©
                if torch.cuda.is_available():
                    # GPUë¡œ ëª¨ë¸ ì´ë™
                    self.model.to(self.device)
                    
                    # CUDA ë²„ì „ í˜¸í™˜ì„± í™•ì¸ í›„ ìµœì í™” ì ìš©
                    try:
                        # float ìƒíƒœì—ì„œ fuse ì‹œë„
                        self.model.float()
                        self.model.fuse()
                        # fuse ì„±ê³µ ì‹œ half precision ì ìš©
                        if self.device.type == 'cuda':
                            self.model.half()
                        logger.info("ëª¨ë¸ GPU ìµœì í™” ì™„ë£Œ (fuse + half precision)")
                    except RuntimeError as cuda_err:
                        # CUDA ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ floatë¡œ í´ë°±
                        logger.warning(f"CUDA ìµœì í™” ì‹¤íŒ¨, CPUë¡œ í´ë°±: {str(cuda_err)}")
                        self.model.cpu().float()
                        self.device = torch.device("cpu")
                        logger.info("CPU ëª¨ë“œë¡œ ì „í™˜ë¨")
                else:
                    # CUDAê°€ ì—†ìœ¼ë©´ CPU ì‚¬ìš©
                    self.model.cpu().float()
                    self.device = torch.device("cpu")
                    logger.info("CPU ëª¨ë“œë¡œ ëª¨ë¸ ì´ˆê¸°í™”")
                    
            except Exception as model_opt_err:
                # ëª¨ë¸ ìµœì í™” ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ í´ë°±
                logger.error(f"ëª¨ë¸ ìµœì í™” ì¤‘ ì˜¤ë¥˜: {str(model_opt_err)}")
                self.model.cpu().float()
                self.device = torch.device("cpu")
                logger.info("ê¸°ë³¸ CPU ëª¨ë“œë¡œ í´ë°± ì™„ë£Œ")

            logger.info("ëª¨ë¸ ë¡œë“œ ë° ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}")
            logger.error(traceback.format_exc())
            raise

        # ì¶”ì ê¸° ë° ìƒíƒœ ë³€ìˆ˜
        self.tracker = EuclideanDistTracker()
        self.object_movements = {}
        self.gravity_direction_threshold = 6
        self.detected_vehicles = set()
        self.vehicle_tracking = {}
        self.violation_vehicles = set()
        self.vehicle_classes = [2, 5, 7]  # car, bus, truck
        
        # DetectionStrategyManager ì´ˆê¸°í™” ë° ì „ëµ ë“±ë¡
        self.strategy_manager = DetectionStrategyManager()
        self._initialize_detection_strategies()

        # í”„ë ˆì„ ë²„í¼ ì„¤ì •
        self.continuous_buffer = deque(maxlen=300)  # ì ì ˆí•œ í¬ê¸°ë¡œ ì´ˆê¸°í™”
        self.continuous_buffer_maxlen = 300  # ë‚˜ì¤‘ì— fpsì— ë§ê²Œ ì¡°ì •ë¨
        self.buffer_lock = threading.Lock()
        self.buffer_duration = 2  # ì´ë²¤íŠ¸ ì „ ë²„í¼ë§í•  ì‹œê°„(ì´ˆ)
        self.post_event_duration = 5  # ì´ë²¤íŠ¸ í›„ ë…¹í™”í•  ì‹œê°„(ì´ˆ)
        self.fps = 30  # ê¸°ë³¸ê°’, ì‹¤ì œ ê°’ì€ validate_video_fileì—ì„œ ì„¤ì •ë¨
        self.current_frame_index = 0

        # VideoWriterThread ì´ˆê¸°í™” ì „ í•„ìš”í•œ í
        self.write_queue = queue.Queue()
        self.writer_thread = None

        # ì´ë²¤íŠ¸ ê´€ë ¨ ë³€ìˆ˜
        self.event_lock = threading.Lock()
        self.event_active = False
        self.event_triggered_at = 0

        # ì˜ìƒ ë””ì½”ë”©ìš©
        self.frame_queue = queue.Queue(maxsize=20)  # ì ì ˆí•œ í í¬ê¸° ì„¤ì •
        self.run_flag = threading.Event()
        self.run_flag.set()  # True ìƒíƒœ

    def _initialize_detection_strategies(self):
        """ê°ì§€ ì „ëµë“¤ì„ ë“±ë¡í•˜ê³  í™œì„±í™”í•˜ëŠ” í•¨ìˆ˜"""
        try:
            # ì „ëµ ë“±ë¡
            self.strategy_manager.register_strategy("size_range", SizeRangeStrategy())
            self.strategy_manager.register_strategy("gravity_direction", GravityDirectionStrategy())
            self.strategy_manager.register_strategy("vehicle_distance", VehicleDistanceStrategy())
            self.strategy_manager.register_strategy("vehicle_overlap", VehicleOverlapStrategy())
            self.strategy_manager.register_strategy("direction_alignment", DirectionAlignmentStrategy())
            self.strategy_manager.register_strategy("vehicle_association", VehicleAssociationStrategy())
            
            # ê¸°ë³¸ ì „ëµ í™œì„±í™”
            self.strategy_manager.enable_strategy("size_range")
            self.strategy_manager.enable_strategy("gravity_direction")
            self.strategy_manager.enable_strategy("vehicle_distance")
            
            logger.info(f"DetectionStrategyManager ì´ˆê¸°í™” ì™„ë£Œ: {len(self.strategy_manager.get_enabled_strategies())}ê°œ ì „ëµ í™œì„±í™”")
            
        except Exception as e:
            logger.error(f"ì „ëµ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}")
            logger.error(traceback.format_exc())

    def debug_detection_info(self, obj_id, bbox, is_detected, strategies_result=None):
        """ê°ì²´ ê²€ì¶œ ì •ë³´ë¥¼ ë””ë²„ê¹… ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ - í–¥ìƒëœ ë²„ì „"""
        if not self.config.debug_detection:
            return  # ë””ë²„ê¹… ëª¨ë“œê°€ ì•„ë‹ˆë©´ ì¶œë ¥í•˜ì§€ ì•ŠìŒ

        # bbox í˜•ì‹ ì •ê·œí™” ë° ì¢Œí‘œ ì¶”ì¶œ
        try:
            # bboxê°€ tuple ì•ˆì— tupleì¸ ê²½ìš° ì²˜ë¦¬
            if isinstance(bbox, tuple) and len(bbox) == 2 and isinstance(bbox[0], tuple):
                bbox = bbox[0]  # ì²« ë²ˆì§¸ tupleë§Œ ì‚¬ìš©
            
            if len(bbox) == 4:
                x, y, w, h = bbox
                # w, hê°€ ìŒìˆ˜ì¸ ê²½ìš° (x1,y1,x2,y2) í˜•ì‹ìœ¼ë¡œ ê°„ì£¼
                if w < 0 or h < 0:
                    x1, y1, x2, y2 = bbox
                    x, y = x1, y1
                    w, h = x2 - x1, y2 - y1
                    # ì—¬ì „íˆ ìŒìˆ˜ë©´ ì ˆëŒ“ê°’ ì‚¬ìš©
                    w, h = abs(w), abs(h)
            else:
                x, y, w, h = 0, 0, 0, 0
                print(f"âš ï¸  ê²½ê³ : ì˜ëª»ëœ bbox í˜•ì‹: {bbox}")
                
        except Exception as e:
            x, y, w, h = 0, 0, 0, 0
            print(f"âš ï¸  ê²½ê³ : bbox ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}, bbox: {bbox}")
        
        status = "âœ…ì„±ê³µ" if is_detected else "âŒì‹¤íŒ¨"
        area = w * h
        
        # ê°ì²´ ì¶”ì  ì •ë³´ ì¶”ê°€
        tracking_info = self.object_movements.get(obj_id, {})
        frame_count = tracking_info.get("count", 0)
        trajectory_length = len(tracking_info.get("trajectory", []))
        
        print(f"\n{'='*60}")
        print(f"ğŸ¯ [ê°ì²´ ì¶”ì  ë””ë²„ê¹…] ID: {obj_id}")
        print(f"ğŸ“ ì¢Œí‘œ: ({x}, {y}) í¬ê¸°: {w} x {h} (ë©´ì : {area} í”½ì…€)")
        print(f"ğŸ“Š í”„ë ˆì„ ì¹´ìš´íŠ¸: {frame_count}/{self.config.min_frame_count_for_violation}")
        print(f"ğŸ“ˆ ê¶¤ì  ê¸¸ì´: {trajectory_length}")
        print(f"ğŸ¯ ìµœì¢… ê²€ì¶œ: {status}")
        print(f"âš™ï¸  ë¡œì§ ëª¨ë“œ: {self.config.detection_logic}")
        
        # í¬ê¸° ë²”ìœ„ ì²´í¬ ì¶”ê°€
        size_status = "âœ…" if self.config.min_size <= area <= self.config.max_size else "âŒ"
        print(f"ğŸ“ í¬ê¸° ì²´í¬: {size_status} (ë²”ìœ„: {self.config.min_size} ~ {self.config.max_size} í”½ì…€)")

        # ì „ëµë³„ ê²°ê³¼ê°€ ìˆë‹¤ë©´ ìƒì„¸ ì¶œë ¥
        if strategies_result and isinstance(strategies_result, dict):
            print(f"\nğŸ“‹ [ì „ëµë³„ ìƒì„¸ ê²°ê³¼]")
            for strategy_id, result in strategies_result.items():
                status_icon = "âœ…" if result else "âŒ"
                strategy_name = "ì•Œ ìˆ˜ ì—†ëŠ” ì „ëµ"
                
                # ì „ëµ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                if hasattr(self, 'strategy_manager') and strategy_id in self.strategy_manager.strategies:
                    strategy_name = self.strategy_manager.strategies[strategy_id].name()
                
                print(f"  {status_icon} {strategy_id} ({strategy_name}): {result}")

        # ê°ì²´ ê¶¤ì  ì •ë³´ ì¶œë ¥
        if trajectory_length > 1:
            trajectory = tracking_info.get("trajectory", [])
            recent_positions = trajectory[-min(5, len(trajectory)):]  # ìµœê·¼ 5ê°œ ìœ„ì¹˜
            
            print(f"\nğŸ“ [ìµœê·¼ ì´ë™ ê²½ë¡œ] (ìµœê·¼ {len(recent_positions)}ê°œ ìœ„ì¹˜)")
            for i, pos_info in enumerate(recent_positions):
                center = pos_info.get('center', (0, 0))
                print(f"  {i+1}. ({center[0]}, {center[1]})")
                
            # ì´ë™ ë°©í–¥ ê³„ì‚° ë° ì¶œë ¥
            if len(recent_positions) >= 2:
                first_pos = recent_positions[0]['center']
                last_pos = recent_positions[-1]['center']
                dx = last_pos[0] - first_pos[0]
                dy = last_pos[1] - first_pos[1]
                
                direction = "ì •ì§€"
                if abs(dx) > 3 or abs(dy) > 3:  # ìµœì†Œ ì´ë™ ê±°ë¦¬
                    if abs(dx) > abs(dy):
                        direction = "ìš°ì¸¡" if dx > 0 else "ì¢Œì¸¡"
                    else:
                        direction = "í•˜ê°•" if dy > 0 else "ìƒìŠ¹"
                
                print(f"  ğŸ§­ ì´ë™ ë°©í–¥: {direction} (dx: {dx:+.1f}, dy: {dy:+.1f})")

        print(f"{'='*60}\n")

    def debug_strategy_details(self, obj_id, tracking_info, vehicle_info):
        """ì „ëµë³„ ìƒì„¸ ë¶„ì„ ì •ë³´ë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜"""
        if not self.config.debug_detection:
            return

        if not tracking_info or len(tracking_info) < 1:
            return

        print(f"\nğŸ” [ì „ëµë³„ ìƒì„¸ ë¶„ì„] ê°ì²´ ID: {obj_id}")
        
        # í˜„ì¬ ê°ì²´ ì •ë³´
        current_info = tracking_info[-1]
        current_center = current_info['center']
        current_bbox = current_info['bbox']
        
        # 1. í¬ê¸° ë²”ìœ„ ì „ëµ ë¶„ì„
        width = current_bbox[2] - current_bbox[0]
        height = current_bbox[3] - current_bbox[1]
        area = width * height
        size_valid = self.config.min_size <= area <= self.config.max_size
        print(f"ğŸ“ í¬ê¸° ë¶„ì„: ë©´ì ={area} (ë²”ìœ„: {self.config.min_size}-{self.config.max_size}) {'âœ…' if size_valid else 'âŒ'}")
        
        # 2. ì¤‘ë ¥ ë°©í–¥ ì „ëµ ë¶„ì„
        if len(tracking_info) >= 2:
            y_movements = []
            for i in range(1, len(tracking_info)):
                prev_y = tracking_info[i-1]['center'][1]
                curr_y = tracking_info[i]['center'][1]
                y_diff = curr_y - prev_y
                y_movements.append(y_diff)
            
            downward_moves = sum(1 for diff in y_movements if diff >= 1)
            total_moves = len(y_movements)
            downward_ratio = downward_moves / total_moves if total_moves > 0 else 0
            
            print(f"â¬‡ï¸  ì¤‘ë ¥ ë¶„ì„: í•˜ê°• ì›€ì§ì„ {downward_moves}/{total_moves} ({downward_ratio:.1%}) {'âœ…' if downward_ratio >= 0.8 else 'âŒ'}")
        
        # 3. ì°¨ëŸ‰ ê±°ë¦¬ ì „ëµ ë¶„ì„
        if vehicle_info:
            min_distance = float('inf')
            closest_vehicle = None
            
            for i, vehicle in enumerate(vehicle_info):
                veh_center = vehicle['center']
                distance = math.sqrt((current_center[0] - veh_center[0])**2 + (current_center[1] - veh_center[1])**2)
                if distance < min_distance:
                    min_distance = distance
                    closest_vehicle = i
            
            distance_valid = min_distance <= self.config.distance_trash
            print(f"ğŸš— ì°¨ëŸ‰ ê±°ë¦¬: ìµœê·¼ì ‘={min_distance:.1f}px (ê¸°ì¤€: {self.config.distance_trash}px) {'âœ…' if distance_valid else 'âŒ'}")
            
            if closest_vehicle is not None:
                vehicle = vehicle_info[closest_vehicle]
                veh_bbox = vehicle['bbox']
                print(f"    ê°€ì¥ ê°€ê¹Œìš´ ì°¨ëŸ‰: ({veh_bbox[0]}, {veh_bbox[1]}, {veh_bbox[2]}, {veh_bbox[3]})")
        else:
            print(f"ğŸš— ì°¨ëŸ‰ ê±°ë¦¬: ì°¨ëŸ‰ ì •ë³´ ì—†ìŒ âŒ")
        
        # 4. ì°¨ëŸ‰ ê²¹ì¹¨ ì „ëµ ë¶„ì„
        if vehicle_info:
            overlap_detected = False
            for vehicle in vehicle_info:
                veh_bbox = vehicle['bbox']
                
                # ì¤‘ì‹¬ì ì´ ì°¨ëŸ‰ ë‚´ë¶€ì— ìˆëŠ”ì§€ í™•ì¸
                if (veh_bbox[0] <= current_center[0] <= veh_bbox[2] and
                    veh_bbox[1] <= current_center[1] <= veh_bbox[3]):
                    overlap_detected = True
                    print(f"ğŸš« ì°¨ëŸ‰ ê²¹ì¹¨: ê°ì²´ ì¤‘ì‹¬ì ì´ ì°¨ëŸ‰ ë‚´ë¶€ì— ìœ„ì¹˜ âŒ")
                    break
            
            if not overlap_detected:
                print(f"ğŸš« ì°¨ëŸ‰ ê²¹ì¹¨: ì°¨ëŸ‰ê³¼ ê²¹ì¹˜ì§€ ì•ŠìŒ âœ…")
        else:
            print(f"ğŸš« ì°¨ëŸ‰ ê²¹ì¹¨: ì°¨ëŸ‰ ì •ë³´ ì—†ìŒ âœ…")
        
        print()  # ë¹ˆ ì¤„ ì¶”ê°€

    def validate_video_file(self, file_path: str) -> bool:
        """
        ì´ í•¨ìˆ˜ì—ì„œëŠ” ë¹„ë””ì˜¤ íŒŒì¼ì˜ ê¸°ë³¸ ìœ íš¨ì„±ë§Œ í™•ì¸.
        ë””ì½”ë”© ìŠ¤ë ˆë“œëŠ” ì´í›„ ë³„ë„ Thread(FrameReaderThread)ì—ì„œ ë‹´ë‹¹.
        """
        try:
            valid_extensions = ['.mp4', '.avi', '.mov', '.mkv']
            file_ext = os.path.splitext(file_path)[1].lower()

            if not any(file_ext == ext for ext in valid_extensions):
                logger.warning(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_path} (í™•ì¥ì: {file_ext})")
                return False

            if not os.path.exists(file_path):
                logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path}")
                return False

            # ë©”íƒ€ë°ì´í„°ë§Œ ì¼ë‹¨ í™•ì¸
            cap = cv2.VideoCapture(file_path)
            if not cap.isOpened():
                logger.error(f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŒ: {file_path}")
                return False

            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            cap.release()

            if total_frames <= 0 or fps <= 0 or width <= 0 or height <= 0:
                logger.warning(f"ì˜ëª»ëœ ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„°: {file_path} (í”„ë ˆì„ ìˆ˜: {total_frames}, FPS: {fps}, í•´ìƒë„: {width}x{height})")
                return False

            self.fps = fps
            self.config.fps = self.fps

            # ë²„í¼ í¬ê¸° ì„¤ì • - ì´ë²¤íŠ¸ ì „í›„ ì‹œê°„ì„ ê³ ë ¤í•˜ì—¬ ê³„ì‚°
            total_buffer_duration = self.buffer_duration + self.post_event_duration + 1
            self.continuous_buffer_maxlen = int(self.fps * total_buffer_duration)
            self.continuous_buffer = deque(maxlen=self.continuous_buffer_maxlen)

            logger.info(
                f"FPS ì„¤ì •: {self.fps}, ì—°ì† ë²„í¼ í¬ê¸°: {self.continuous_buffer_maxlen} í”„ë ˆì„ (ì´ {total_buffer_duration}ì´ˆ)")

            # VideoWriterThread ìƒì„±
            if self.writer_thread is None:
                self.writer_thread = VideoWriterThread(
                    self.write_queue, self.config, self.roi_x, self.roi_y,
                    self.roi_width, self.roi_height
                )
            return True
        except cv2.error as cv_err:
            logger.error(f"OpenCV ì˜¤ë¥˜: {str(cv_err)}")
            logger.error(traceback.format_exc())
            return False
        except IOError as io_err:
            logger.error(f"íŒŒì¼ IO ì˜¤ë¥˜: {str(io_err)}")
            logger.error(traceback.format_exc())
            return False
        except Exception as e:
            logger.error(f"ë¹„ë””ì˜¤ íŒŒì¼ ê²€ì¦ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}")
            logger.error(traceback.format_exc())
            return False

    def clear_buffers(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ìœ„í•´ ëª¨ë“  ë²„í¼ë¥¼ ë¹„ìš°ëŠ” ë©”ì„œë“œ"""
        with self.buffer_lock:
            self.continuous_buffer.clear()

        with self.batch_lock:
            if hasattr(self, 'batch_frames'):
                self.batch_frames = []
            if hasattr(self, 'batch_originals'):
                self.batch_originals = []

        # ì¶”ì  ë°ì´í„° ì •ë¦¬
        self.object_movements.clear()
        self.detected_vehicles.clear()
        self.vehicle_tracking.clear()
        self.violation_vehicles.clear()

        # í ë¹„ìš°ê¸°
        while not self.frame_queue.empty():
            try:
                self.frame_queue.get_nowait()
            except queue.Empty:
                break

        logger.debug("ëª¨ë“  ë²„í¼ì™€ ì¶”ì  ë°ì´í„° ì •ë¦¬ ì™„ë£Œ")

    def run(self):
        """
        ë©”ì¸ ì¶”ë¡  ë£¨í”„:
         1) FrameReaderThreadì—ì„œ ë””ì½”ë”©ëœ frameì„ queueì—ì„œ êº¼ëƒ„
         2) ë°°ì¹˜ êµ¬ì„± -> YOLO ì¶”ë¡  -> í›„ì²˜ë¦¬
        """
        if not self.validate_video_file(self.video_path):
            logger.error(f"ë¹„ë””ì˜¤ íŒŒì¼ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.video_path}")
            return

        # ë””ì½”ë”© ìŠ¤ë ˆë“œ ì‹œì‘
        self.reader_thread = FrameReaderThread(
            self.video_path,
            frame_queue=self.frame_queue,
            run_flag=self.run_flag
        )

        try:
            object_detector = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=95)

            frame_count = 0
            start_time = time.time()

            BATCH_SIZE = self.config.batch_size
            batch_frames = []
            batch_originals = []

            while self._run_flag:
                try:
                    # ë””ì½”ë”© ìŠ¤ë ˆë“œê°€ íì— ë„£ì€ í”„ë ˆì„ì„ ê°€ì ¸ì˜´ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
                    frame = self.frame_queue.get(timeout=1.0)

                    # Noneì´ë©´ EOF ë˜ëŠ” ì˜¤ë¥˜ -> ì¢…ë£Œ
                    if frame is None:
                        logger.info("VideoThread: í”„ë ˆì„ì´ None -> ë””ì½”ë”© ì¢…ë£Œ ì‹ í˜¸")
                        # ì´ë²¤íŠ¸ê°€ í™œì„±í™”ëœ ìƒíƒœì—ì„œ EOF ë„ë‹¬ ì‹œ ê°•ì œ ì €ì¥
                        if self.event_active:
                            self.collect_post_event_frame(None, roi_x1, roi_y1)
                        break

                    self.current_frame_index += 1
                    process_frame = frame.copy()

                    # ì—°ì† ë²„í¼ì— í”„ë ˆì„ ì¶”ê°€ (ì´ë²¤íŠ¸ ì „í›„ ë…¹í™”ìš©)
                    with self.buffer_lock:
                        self.continuous_buffer.append(frame.copy())

                    # ROI ì˜ì—­ì´ í”„ë ˆì„ ê²½ê³„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ ë³´ì •
                    roi_x1 = max(0, min(self.roi_x, frame.shape[1]))
                    roi_y1 = max(0, min(self.roi_y, frame.shape[0]))
                    roi_x2 = max(0, min(self.roi_x + self.roi_width, frame.shape[1]))
                    roi_y2 = max(0, min(self.roi_y + self.roi_height, frame.shape[0]))

                    # ROI ì˜ì—­ í‘œì‹œ
                    cv2.rectangle(process_frame, (roi_x1, roi_y1), (roi_x2, roi_y2), (255, 255, 0), 2)

                    # ROI ì¶”ì¶œ
                    if roi_y2 > roi_y1 and roi_x2 > roi_x1:  # ìœ íš¨í•œ ROI í¬ê¸° í™•ì¸
                        roi_frame = frame[roi_y1:roi_y2, roi_x1:roi_x2].copy()
                    else:
                        logger.warning(
                            f"ìœ íš¨í•˜ì§€ ì•Šì€ ROI í¬ê¸°: x={roi_x1}, y={roi_y1}, width={roi_x2 - roi_x1}, height={roi_y2 - roi_y1}")
                        continue

                    # ë°°ì¹˜ ìŒ“ê¸° (ë½ ì‚¬ìš©)
                    with self.batch_lock:
                        batch_frames.append(roi_frame)
                        batch_originals.append(process_frame)

                    # ë°°ì¹˜ ì¶”ë¡ 
                    if len(batch_frames) >= BATCH_SIZE:
                        with self.batch_lock:
                            # í˜„ì¬ ë°°ì¹˜ ë³µì‚¬ í›„ ë°°ì¹˜ ì´ˆê¸°í™”
                            current_batch_frames = batch_frames.copy()
                            current_batch_originals = batch_originals.copy()
                            batch_frames.clear()
                            batch_originals.clear()

                        # ë°°ì¹˜ ì¶”ë¡  ì‹¤í–‰
                        try:
                            results = self.model(
                                current_batch_frames,
                                verbose=False,
                                device=self.device
                            )

                            for i, result in enumerate(results):
                                original_frame = current_batch_originals[i]
                                roi_for_bg = current_batch_frames[i]

                                yolo_boxes = self.parse_yolo_results(result, roi_x1, roi_y1)

                                contour_detections = self.detect_litter_candidates(
                                    roi_for_bg, object_detector, roi_x1, roi_y1, yolo_boxes
                                )

                                tracked_objects = self.tracker.update(contour_detections)
                                self.analyze_tracked_objects(
                                    original_frame, tracked_objects, yolo_boxes
                                )
                                self.mark_vehicles(original_frame, yolo_boxes)

                                self.change_pixmap_signal.emit(original_frame)

                                # ì´ë²¤íŠ¸ê°€ í™œì„±í™”ëœ ê²½ìš° collect_post_event_frame í˜¸ì¶œ
                                if self.event_active:
                                    self.collect_post_event_frame(frame, roi_x1, roi_y1)

                                # FPS ê³„ì‚°
                                frame_count += 1
                                elapsed_time = time.time() - start_time
                                if elapsed_time >= 1.0:
                                    fps_show = frame_count / elapsed_time
                                    logger.info(f"í˜„ì¬ FPS: {fps_show:.2f}")
                                    frame_count = 0
                                    start_time = time.time()
                        except torch.cuda.OutOfMemoryError:
                            logger.error("CUDA ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜ ë°œìƒ. ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”.")
                        except Exception as e:
                            logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                            logger.error(traceback.format_exc())

                except queue.Empty:
                    # íƒ€ì„ì•„ì›ƒ ë°œìƒ - ì •ì§€ ì‹ í˜¸ í™•ì¸
                    if not self._run_flag:
                        break
                    continue

            # ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬
            with self.batch_lock:
                remaining_batch_frames = batch_frames.copy()
                remaining_batch_originals = batch_originals.copy()
                batch_frames.clear()
                batch_originals.clear()

            if remaining_batch_frames:
                try:
                    results = self.model(
                        remaining_batch_frames,
                        verbose=False,
                        device=self.device
                    )
                    for i, result in enumerate(results):
                        original_frame = remaining_batch_originals[i]
                        roi_for_bg = remaining_batch_frames[i]

                        yolo_boxes = self.parse_yolo_results(result, roi_x1, roi_y1)
                        contour_detections = self.detect_litter_candidates(
                            roi_for_bg, object_detector, roi_x1, roi_y1, yolo_boxes
                        )
                        tracked_objects = self.tracker.update(contour_detections)
                        self.analyze_tracked_objects(
                            original_frame, tracked_objects, yolo_boxes
                        )
                        self.mark_vehicles(original_frame, yolo_boxes)
                        self.change_pixmap_signal.emit(original_frame)

                        # ì´ë²¤íŠ¸ê°€ í™œì„±í™”ëœ ê²½ìš° collect_post_event_frame í˜¸ì¶œ
                        if self.event_active:
                            self.collect_post_event_frame(frame, roi_x1, roi_y1)
                except Exception as e:
                    logger.error(f"ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    logger.error(traceback.format_exc())

        except torch.cuda.OutOfMemoryError as cuda_err:
            logger.error(f"CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±: {str(cuda_err)}")
            logger.error(traceback.format_exc())
        except cv2.error as cv_err:
            logger.error(f"OpenCV ì˜¤ë¥˜: {str(cv_err)}")
            logger.error(traceback.format_exc())
        except Exception as e:
            logger.error(f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(traceback.format_exc())
        finally:
            # ìŠ¤ë ˆë“œ ì¢…ë£Œ ì²˜ë¦¬
            self.run_flag.clear()

            try:
                if hasattr(self, 'reader_thread') and self.reader_thread is not None:
                    self.reader_thread.join(timeout=2.0)
                    if self.reader_thread.is_alive():
                        logger.warning("FrameReaderThreadê°€ ì‹œê°„ ë‚´ì— ì¢…ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            except Exception as e:
                logger.error(f"FrameReaderThread ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {str(e)}")

            try:
                if self.writer_thread:
                    self.writer_thread.stop()
                    self.writer_thread.join(timeout=2.0)
                    if self.writer_thread.is_alive():
                        logger.warning("VideoWriterThreadê°€ ì‹œê°„ ë‚´ì— ì¢…ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            except Exception as e:
                logger.error(f"VideoWriterThread ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {str(e)}")

            # ë©”ëª¨ë¦¬ í•´ì œ ë° ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            self.clear_buffers()
            cv2.destroyAllWindows()
            logger.info("VideoThread: ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")

    def analyze_tracked_objects(self, frame, tracked_objects, yolo_boxes):
        roi_x1 = self.roi_x
        roi_y1 = self.roi_y
        roi_x2 = self.roi_x + self.roi_width
        roi_y2 = self.roi_y + self.roi_height

        # ì°¨ëŸ‰ ì •ë³´ ë³€í™˜ (yolo_boxesë¥¼ ì „ëµ í´ë˜ìŠ¤ê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ)
        vehicle_info = self.get_vehicle_info_from_boxes(yolo_boxes)

        for (x, y, w, h, obj_id) in tracked_objects:
            current_center = (x + w // 2, y + h // 2)
            area = w * h

            if not (self.min_size <= area <= self.max_size):
                if obj_id in self.object_movements:
                    del self.object_movements[obj_id]
                continue

            cv2.putText(frame, f"ID {obj_id}", (x, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

            # ê°ì²´ ì´ë ¥ ì—…ë°ì´íŠ¸
            if obj_id not in self.object_movements:
                # ìƒˆ ê°ì²´ ì´ˆê¸°í™”
                self.object_movements[obj_id] = {
                    "trajectory": [{'center': current_center, 'bbox': (x, y, x + w, y + h), 'class_name': 'litter',
                                    'confidence': 1.0}],
                    "count": 1,
                    "video_saved": False,
                    "related_vehicle": None,
                    "movement_direction": None,
                    "last_update": time.time()
                }
            else:
                # ê¸°ì¡´ ê°ì²´ì˜ ê²½ìš° ë°ì´í„° í˜•ì‹ í™•ì¸ ë° ì—…ë°ì´íŠ¸
                if not isinstance(self.object_movements[obj_id], dict):
                    # í˜•ì‹ì´ ì˜ëª»ëœ ê²½ìš° ì´ˆê¸°í™”
                    self.object_movements[obj_id] = {
                        "trajectory": [{'center': current_center, 'bbox': (x, y, x + w, y + h), 'class_name': 'litter',
                                        'confidence': 1.0}],
                        "count": 1,
                        "video_saved": False,
                        "related_vehicle": None,
                        "movement_direction": None,
                        "last_update": time.time()
                    }
                else:
                    # trajectory í‚¤ê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
                    if "trajectory" not in self.object_movements[obj_id]:
                        self.object_movements[obj_id]["trajectory"] = []

                    # ì´ì „ ìœ„ì¹˜ì™€ í˜„ì¬ ìœ„ì¹˜ì— ê¸°ë°˜í•œ ì´ë™ ë°©í–¥ ë° ê±°ë¦¬ ê³„ì‚°
                    if len(self.object_movements[obj_id]["trajectory"]) > 0:
                        prev_info = self.object_movements[obj_id]["trajectory"][-1]
                        prev_center = prev_info['center']
                        x_diff = current_center[0] - prev_center[0]
                        y_diff = current_center[1] - prev_center[1]

                        # ì´ë™ ë°©í–¥ ê³„ì‚°
                        if abs(x_diff) > abs(y_diff):
                            # ìˆ˜í‰ ì´ë™ì´ ë” í° ê²½ìš°
                            movement_direction = "right" if x_diff > 0 else "left"
                        else:
                            # ìˆ˜ì§ ì´ë™ì´ ë” í° ê²½ìš°
                            movement_direction = "down" if y_diff > 0 else "up"

                        # ë°©í–¥ ì—…ë°ì´íŠ¸
                        if self.object_movements[obj_id].get("movement_direction") is None:
                            self.object_movements[obj_id]["movement_direction"] = movement_direction

                    # í˜„ì¬ ìœ„ì¹˜ ì •ë³´ ì¶”ê°€
                    self.object_movements[obj_id]["trajectory"].append({
                        'center': current_center,
                        'bbox': (x, y, x + w, y + h),
                        'class_name': 'litter',
                        'confidence': 1.0
                    })

                    # ì¹´ìš´íŠ¸ ì¦ê°€
                    self.object_movements[obj_id]["count"] = self.object_movements[obj_id].get("count", 0) + 1
                    self.object_movements[obj_id]["last_update"] = time.time()

            # DetectionStrategyManagerë¥¼ ì´ìš©í•œ ì²´ê³„ì ì¸ ê°ì§€ ë¡œì§
            if len(self.object_movements[obj_id]["trajectory"]) >= 2:
                # ì¹´ìš´íŠ¸ê°€ ì„ê³„ê°’ì„ ë„˜ì—ˆëŠ”ì§€ í™•ì¸
                count = self.object_movements[obj_id].get("count", 0)
                min_frames = self.config.min_frame_count_for_violation
                
                # ì¹´ìš´íŠ¸ ì„ê³„ê°’ ë¯¸ë‹¬ ì‹œ ê²€ì‚¬ ìŠ¤í‚µ
                if count < min_frames:
                    continue
                
                try:
                    # DetectionStrategyManagerë¥¼ ì‚¬ìš©í•œ ì „ëµ ê²€ì‚¬
                    strategy_results = self.strategy_manager.check_strategies(
                        frame=frame,
                        tracking_info=self.object_movements[obj_id]["trajectory"],
                        config=self.config,
                        vehicle_info=vehicle_info
                    )
                    
                    # Configì˜ detection_logic ì„¤ì •ì— ë”°ë¥¸ ìµœì¢… íŒì •
                    if self.config.detection_logic == "ANY":
                        # í•˜ë‚˜ë¼ë„ Trueë©´ ì„±ê³µ
                        detection_result = any(strategy_results.values()) if strategy_results else False
                    elif self.config.detection_logic == "ALL":
                        # ëª¨ë‘ Trueë©´ ì„±ê³µ
                        detection_result = all(strategy_results.values()) if strategy_results else False
                    else:
                        # ê¸°ë³¸ê°’: ALL
                        detection_result = all(strategy_results.values()) if strategy_results else False
                    
                    # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
                    self.debug_detection_info(obj_id, (x, y, w, h), detection_result, strategy_results)
                    
                    # ìƒì„¸ ì „ëµ ë¶„ì„ ì¶œë ¥ (ê²€ì¶œ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´)
                    if self.config.debug_detection:
                        self.debug_strategy_details(obj_id, self.object_movements[obj_id]["trajectory"], vehicle_info)
                    
                    # ì“°ë ˆê¸° íˆ¬ê¸° ê°ì§€ ì²˜ë¦¬
                    if detection_result and not self.object_movements[obj_id].get("video_saved", False):
                        logger.info(f"ì“°ë ˆê¸° íˆ¬ê¸° ê°ì§€: ID={obj_id}, í”„ë ˆì„ ì¹´ìš´íŠ¸={count}")
                        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)
                        
                        # ì°¨ëŸ‰ê³¼ ìœ„ë°˜ ì—°ê²°
                        self.link_violation_with_vehicle(obj_id, current_center, w)
                        
                        # ì“°ë ˆê¸° íˆ¬ê¸° ê°ì§€ ì‹ í˜¸ ë°œìƒ
                        bbox = (x, y, x + w, y + h)
                        class_name = "litter"
                        confidence = 1.0
                        self.littering_detected_signal.emit(bbox, class_name, confidence, strategy_results)
                        
                        # ì´ë²¤íŠ¸ í™œì„±í™” (ì¤‘ë³µ ë°©ì§€)
                        with self.event_lock:
                            if not self.event_active:
                                self.event_triggered_at = self.current_frame_index
                                self.event_active = True
                                logger.info(f"ì“°ë ˆê¸° íˆ¬ê¸° ì´ë²¤íŠ¸ í™œì„±í™”: í”„ë ˆì„ #{self.event_triggered_at}")
                                self.object_movements[obj_id]["video_saved"] = True
                                
                                # ì´ë²¤íŠ¸ í™œì„±í™” ì§í›„ ì¦‰ì‹œ í•œ ë²ˆ í˜¸ì¶œ (í˜„ì¬ í”„ë ˆì„ì— ëŒ€í•´)
                                self.collect_post_event_frame(frame, roi_x1, roi_y1)
                                
                except Exception as e:
                    logger.error(f"ì „ëµ ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜ (ê°ì²´ ID: {obj_id}): {str(e)}")
                    logger.error(traceback.format_exc())
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ë¡œì§ìœ¼ë¡œ í´ë°±
                    strategy_results = {"error": True}
                    self.debug_detection_info(obj_id, (x, y, w, h), False, strategy_results)

    def check_gravity_direction(self, trajectory):
        """ê¶¤ì ì—ì„œ í•˜ê°• ì›€ì§ì„ì„ í™•ì¸í•˜ëŠ” í•¨ìˆ˜"""
        if len(trajectory) < 2:
            return False

        # ìµœê·¼ ëª‡ ê°œì˜ í¬ì¸íŠ¸ì—ì„œ y ì¢Œí‘œ ë³€í™” í™•ì¸
        points_to_check = min(5, len(trajectory))
        positions = [info['center'] for info in trajectory[-points_to_check:]]

        # y ì¢Œí‘œê°€ ì¦ê°€í•˜ëŠ”ì§€ í™•ì¸ (í•˜ê°• ì›€ì§ì„)
        falling_count = 0
        for i in range(1, len(positions)):
            if positions[i][1] > positions[i - 1][1]:  # y ì¢Œí‘œê°€ ì¦ê°€ (í•˜ê°•)
                falling_count += 1

        # 80% ì´ìƒì˜ ì´ë™ì´ í•˜ê°•ì´ë©´ True
        return falling_count >= int(0.8 * (len(positions) - 1))

    def check_vehicle_distance(self, obj_center, vehicle_info):
        """ê°ì²´ê°€ ì°¨ëŸ‰ ê·¼ì²˜ì— ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜"""
        if not vehicle_info:
            return False

        min_distance = float('inf')

        for vehicle in vehicle_info:
            veh_center = vehicle['center']
            dist = math.sqrt((obj_center[0] - veh_center[0]) ** 2 + (obj_center[1] - veh_center[1]) ** 2)
            min_distance = min(min_distance, dist)

        # ì„¤ì •ëœ ê±°ë¦¬ ì„ê³„ê°’ë³´ë‹¤ ê°€ê¹Œìš°ë©´ True
        return min_distance <= self.config.distance_trash

    def get_vehicle_info_from_boxes(self, boxes):
        """yolo_boxes í˜•ì‹ì„ ì°¨ëŸ‰ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        vehicles = []
        for (x1, y1, x2, y2) in boxes:
            center_x = (x1 + x2) / 2
            center_y = (y1 + y2) / 2
            vehicles.append({
                'bbox': (x1, y1, x2, y2),
                'center': (center_x, center_y)
            })
        return vehicles

    def collect_post_event_frame(self, frame, roi_x, roi_y):
        """ì´ë²¤íŠ¸ ë°œìƒ í›„ í”„ë ˆì„ ìˆ˜ì§‘ ë° ì €ì¥ ê²°ì •"""
        logger.debug(f"collect_post_event_frame í˜¸ì¶œë¨: event_active={self.event_active}")
        if not self.event_active:
            return

        # ì´ë²¤íŠ¸ ë°œìƒ ì´í›„ ê²½ê³¼í•œ í”„ë ˆì„ ìˆ˜ ê³„ì‚°
        frames_since_event = self.current_frame_index - self.event_triggered_at

        # ëª©í‘œ í”„ë ˆì„ ìˆ˜ ê³„ì‚° (ì´ë²¤íŠ¸ ì´í›„ ì €ì¥í•  í”„ë ˆì„ ìˆ˜)
        target_post_frames = int(self.fps * self.post_event_duration)

        # íƒ€ê²Ÿ í”„ë ˆì„ ìˆ˜ì— ë„ë‹¬í•˜ê±°ë‚˜ í”„ë ˆì„ì´ ì—†ì„ ë•Œ(None ì‹ í˜¸) ì˜ìƒ ì €ì¥ ì‹œì‘
        frame_is_none = frame is None
        target_reached = frames_since_event >= target_post_frames

        if target_reached or frame_is_none:
            if frame_is_none:
                logger.info("í”„ë ˆì„ì´ None (ë™ì˜ìƒ ì¢…ë£Œ) - í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ í”„ë ˆì„ìœ¼ë¡œ ì˜ìƒ ì €ì¥")
            else:
                logger.info(f"ì˜ìƒ ì €ì¥ ì‹œì‘: {target_post_frames}í”„ë ˆì„ ëª¨ë‘ ìˆ˜ì§‘ ì™„ë£Œ")

            # ì´ë²¤íŠ¸ í™œì„±í™” ìƒíƒœ í™•ì¸ ë° ë¹„í™œì„±í™”
            with self.event_lock:
                # ì¤‘ë³µ ì €ì¥ ë°©ì§€
                if not self.event_active:
                    return

                # ì´ë²¤íŠ¸ ë¹„í™œì„±í™”
                self.event_active = False

                # ë²„í¼ì—ì„œ ì—°ì†ëœ í”„ë ˆì„ ì¶”ì¶œ
                with self.buffer_lock:
                    # í˜„ì¬ ë²„í¼ ë‚´ìš© ë³µì‚¬
                    buffer_frames = list(self.continuous_buffer)
                    logger.info(f"ë²„í¼ì—ì„œ ì¶”ì¶œí•œ í”„ë ˆì„ ìˆ˜: {len(buffer_frames)}")

                # ì´ë²¤íŠ¸ ë°œìƒ ì‹œì  ê¸°ì¤€ìœ¼ë¡œ ì €ì¥í•  í”„ë ˆì„ ë²”ìœ„ ê³„ì‚°
                pre_event_frames = int(self.fps * self.buffer_duration)
                total_frames = len(buffer_frames)

                # ë²„í¼ì—ì„œ í˜„ì¬ ì´ë²¤íŠ¸ ìœ„ì¹˜ ì°¾ê¸°
                event_position_in_buffer = total_frames - frames_since_event
                logger.info(
                    f"ì´ë²¤íŠ¸ ìœ„ì¹˜: total_frames={total_frames}, event_position={event_position_in_buffer}, pre_event_frames={pre_event_frames}")

                # ì´ë²¤íŠ¸ ì „ í”„ë ˆì„ê³¼ ì´ë²¤íŠ¸ í›„ í”„ë ˆì„ ë¶„ë¦¬
                start_index = max(0, event_position_in_buffer - pre_event_frames)

                # ì—°ì†ëœ í”„ë ˆì„ì„ ì¶”ì¶œí•˜ì—¬ ì €ì¥
                frames_to_save = buffer_frames[start_index:]
                logger.info(f"ì €ì¥í•  ì´ í”„ë ˆì„ ìˆ˜: {len(frames_to_save)}")

                if len(frames_to_save) > 0:
                    logger.info(f"ì—°ì† ì˜ìƒ ì €ì¥ ì‹œì‘: ì´ {len(frames_to_save)} í”„ë ˆì„"
                                f" (ì´ë²¤íŠ¸ ì „ {min(pre_event_frames, event_position_in_buffer)} í”„ë ˆì„,"
                                f" ì´ë²¤íŠ¸ í›„ {frames_since_event} í”„ë ˆì„)")

                    # ì €ì¥ ìš”ì²­
                    try:
                        self.write_queue.put((frames_to_save, []))
                        logger.info("ì˜ìƒ ì €ì¥ ìš”ì²­ ì™„ë£Œ, write_queueì— ì¶”ê°€ë¨")

                        # ë¹„ë””ì˜¤ ê²½ë¡œ ì €ì¥ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë”ë¯¸ ì‹ í˜¸
                        if hasattr(self, 'video_saved_signal'):
                            video_path = os.path.join(self.config.output_dir,
                                                      f"trash_event_{time.strftime('%Y%m%d_%H%M%S')}.avi")
                            self.video_saved_signal.emit(video_path)
                    except Exception as e:
                        logger.error(f"ì˜ìƒ ì €ì¥ ìš”ì²­ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                else:
                    logger.error("ì €ì¥í•  í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤.")

    def parse_yolo_results(self, result, roi_x, roi_y):
        """
        YOLO ëª¨ë¸ ê²°ê³¼ë¥¼ íŒŒì‹±í•˜ì—¬ ì°¨ëŸ‰ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        Args:
            result: YOLO ëª¨ë¸ì˜ ê²°ê³¼ ê°ì²´
            roi_x, roi_y: ROI ì¢Œí‘œ ì˜¤í”„ì…‹

        Returns:
            list: ì°¨ëŸ‰ ë°”ìš´ë”© ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸ [(x1, y1, x2, y2), ...]
        """
        boxes = result.boxes.xyxy.cpu().numpy()
        confidences = result.boxes.conf.cpu().numpy()
        classes = result.boxes.cls.cpu().numpy()

        yolo_boxes = []
        current_vehicles = {}

        for box, confidence, class_id in zip(boxes, confidences, classes):
            if confidence > self.config.yolo_confidence_value and int(class_id) in self.vehicle_classes:
                x1, y1, x2, y2 = map(int, box)
                width = x2 - x1
                height = y2 - y1
                if width < self.min_box_size or height < self.min_box_size:
                    continue
                # ë°”ìš´ë”©ë°•ìŠ¤ë¥¼ ì•½ê°„ shrink
                shrink_amount = 20
                x1 += shrink_amount
                x2 -= shrink_amount
                # ROI ì¢Œí‘œê³„ì—ì„œ ì›ë³¸ ì¢Œí‘œê³„ë¡œ ë³€í™˜
                x1 += roi_x
                y1 += roi_y
                x2 += roi_x
                y2 += roi_y
                yolo_boxes.append((x1, y1, x2, y2))

                # ì°¨ëŸ‰ ì¶”ì ìš© ì¤‘ì‹¬
                center = ((x1 + x2) // 2, (y1 + y2) // 2)
                matched = False
                for vid, prev_center in self.vehicle_tracking.items():
                    dist = math.sqrt((center[0] - prev_center[0]) ** 2 + (center[1] - prev_center[1]) ** 2)
                    if dist < 100:
                        current_vehicles[vid] = center
                        matched = True
                        if vid in self.violation_vehicles:
                            self.detected_vehicles.add((x1, y1, x2, y2))
                        break
                if not matched:
                    new_id = len(self.vehicle_tracking) + 1 if not self.vehicle_tracking else max(
                        self.vehicle_tracking.keys()) + 1
                    current_vehicles[new_id] = center

        # í˜„ì¬ í”„ë ˆì„ì— ì—†ëŠ” ì°¨ëŸ‰ì˜ ìœ„ë°˜ ID ì œê±°
        self.violation_vehicles = {vid for vid in self.violation_vehicles if vid in current_vehicles}

        # í˜„ì¬ í”„ë ˆì„ì˜ ì°¨ëŸ‰ë§Œ ìœ ì§€
        self.vehicle_tracking = current_vehicles

        return yolo_boxes

    def detect_litter_candidates(self, roi_frame, object_detector, roi_x, roi_y, yolo_boxes):
        """
        ë°°ê²½ ì°¨ë¶„ì„ í†µí•´ ì“°ë ˆê¸° í›„ë³´ ê°ì²´ë¥¼ ê²€ì¶œí•˜ëŠ” í•¨ìˆ˜

        Args:
            roi_frame: ROI ì˜ì—­ ì´ë¯¸ì§€
            object_detector: ë°°ê²½ ì°¨ë¶„ ê°ì²´
            roi_x, roi_y: ROI ì¢Œí‘œ
            yolo_boxes: ì°¨ëŸ‰ ë°”ìš´ë”© ë°•ìŠ¤ ëª©ë¡

        Returns:
            list: ê²€ì¶œëœ ê°ì²´ ë¦¬ìŠ¤íŠ¸ [x, y, w, h]
        """
        try:
            # ë°°ê²½ ì°¨ë¶„ ì ìš©
            mask = object_detector.apply(roi_frame)

            # ì„ê³„ê°’ ì ìš©
            _, mask = cv2.threshold(mask, 200, 250, cv2.THRESH_BINARY)

            # ë…¸ì´ì¦ˆ ì œê±°
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)

            # ìœ¤ê³½ì„  ê²€ì¶œ
            contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

            # ë””ë²„ê¹… ë¡œê·¸
            logger.debug(f"ë°°ê²½ ì°¨ë¶„ í›„ ê²€ì¶œëœ ìœ¤ê³½ì„  ìˆ˜: {len(contours)}")

            contour_detections = []
            for cnt in contours:
                # ë©´ì  ê³„ì‚°
                area = cv2.contourArea(cnt)

                # í¬ê¸° í•„í„°ë§
                if self.min_size < area < self.max_size:
                    x, y, w, h = cv2.boundingRect(cnt)

                    # ROI ë‚´ì˜ ì¢Œí‘œë¥¼ ì „ì²´ í”„ë ˆì„ ì¢Œí‘œë¡œ ë³€í™˜
                    x += roi_x
                    y += roi_y

                    # ì°¨ëŸ‰ ë°”ìš´ë”©ë°•ìŠ¤ì™€ ê²¹ì¹˜ë©´ ì“°ë ˆê¸°ê°€ ì•„ë‹Œ ê²ƒìœ¼ë¡œ ê°„ì£¼
                    overlap = False
                    overlap_ratio = 0

                    for bx1, by1, bx2, by2 in yolo_boxes:
                        # ë°”ìš´ë”© ë°•ìŠ¤ ë©´ì 
                        obj_area = w * h

                        # ê²¹ì¹˜ëŠ” ì˜ì—­ ê³„ì‚°
                        intersection_x1 = max(x, bx1)
                        intersection_y1 = max(y, by1)
                        intersection_x2 = min(x + w, bx2)
                        intersection_y2 = min(y + h, by2)

                        if intersection_x1 < intersection_x2 and intersection_y1 < intersection_y2:
                            intersection_area = (intersection_x2 - intersection_x1) * (
                                        intersection_y2 - intersection_y1)
                            overlap_ratio = intersection_area / obj_area

                            # ê²¹ì¹¨ ë¹„ìœ¨ì´ ì„ê³„ê°’ ì´ìƒì´ë©´ ê°ì²´ ì œì™¸
                            if overlap_ratio > 0.5:  # ì„ê³„ê°’ì€ í•„ìš”ì— ë”°ë¼ ì¡°ì •
                                overlap = True
                                break

                    # ì°¨ëŸ‰ê³¼ ê²¹ì¹˜ì§€ ì•ŠëŠ” ê°ì²´ë§Œ ì¶”ê°€
                    if not overlap:
                        contour_detections.append([x, y, w, h])
                        logger.debug(f"ì“°ë ˆê¸° í›„ë³´ ê²€ì¶œ: ìœ„ì¹˜=({x},{y}), í¬ê¸°={w}x{h}, ë©´ì ={area}")

            logger.debug(f"ìµœì¢… ê²€ì¶œëœ ì“°ë ˆê¸° í›„ë³´ ê°ì²´ ìˆ˜: {len(contour_detections)}")
            return contour_detections

        except Exception as e:
            logger.error(f"ì“°ë ˆê¸° í›„ë³´ ê²€ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(traceback.format_exc())
            return []

    def mark_vehicles(self, frame, yolo_boxes):
        """
        í”„ë ˆì„ì— ì°¨ëŸ‰ì„ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜ (ìœ„ë°˜ ì°¨ëŸ‰ì€ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ ê°•ì¡°)

        Args:
            frame: í‘œì‹œí•  í”„ë ˆì„
            yolo_boxes: ì°¨ëŸ‰ ë°”ìš´ë”© ë°•ìŠ¤ ëª©ë¡
        """
        for (bx1, by1, bx2, by2) in yolo_boxes:
            is_violation = False
            box_center = ((bx1 + bx2) // 2, (by1 + by2) // 2)

            for vid, center in self.vehicle_tracking.items():
                dist = math.sqrt((box_center[0] - center[0]) ** 2 + (box_center[1] - center[1]) ** 2)
                if dist < 50 and vid in self.violation_vehicles:
                    is_violation = True
                    break

            if is_violation or (bx1, by1, bx2, by2) in self.detected_vehicles:
                cv2.rectangle(frame, (bx1, by1), (bx2, by2), (0, 0, 255), 2)
                cv2.putText(frame, "Violation Vehicle", (bx1, by1 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
            else:
                cv2.rectangle(frame, (bx1, by1), (bx2, by2), (255, 0, 0), 2)
                cv2.putText(frame, "Vehicle", (bx1, by1 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

    def link_violation_with_vehicle(self, obj_id, litter_center, litter_width):
        """
        ì“°ë ˆê¸° íˆ¬ê¸° ê°ì²´ë¥¼ ì£¼ë³€ ì°¨ëŸ‰ê³¼ ì—°ê²°í•˜ëŠ” í•¨ìˆ˜

        Args:
            obj_id: ì“°ë ˆê¸° ê°ì²´ ID
            litter_center: ì“°ë ˆê¸° ê°ì²´ ì¤‘ì‹¬ì 
            litter_width: ì“°ë ˆê¸° ê°ì²´ ë„ˆë¹„
        """
        for vid, center in self.vehicle_tracking.items():
            vehicle_left_mid = (center[0] - litter_width // 2, center[1])
            vehicle_right_mid = (center[0] + litter_width // 2, center[1])

            distance1 = math.sqrt((litter_center[0] - vehicle_left_mid[0]) ** 2 +
                                  (litter_center[1] - vehicle_left_mid[1]) ** 2)
            distance2 = math.sqrt((litter_center[0] - vehicle_right_mid[0]) ** 2 +
                                  (litter_center[1] - vehicle_right_mid[1]) ** 2)

            if distance1 <= self.config.distance_trash or distance2 <= self.config.distance_trash:
                logger.info(f"Vehicle ID: {vid}, Distance1: {distance1}, Distance2: {distance2}")
                self.violation_vehicles.add(vid)

                # ë”•ì…”ë„ˆë¦¬ ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •
                if obj_id in self.object_movements and isinstance(self.object_movements[obj_id], dict):
                    self.object_movements[obj_id]["video_saved"] = True
                break
